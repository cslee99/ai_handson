{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AMC_MI2RL_Medical_Image_Classification_HJBae_20190731.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6GWbSx9-KNd",
        "colab_type": "text"
      },
      "source": [
        "# 2019 KOSAIM Summer School\n",
        "\n",
        "#Deep Learning Hands-on (2): Medical Image Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3SbO4_C-mxh",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://adeshpande3.github.io/assets/Cover.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WaZl5UEFoiY",
        "colab_type": "text"
      },
      "source": [
        "# 0. 시작에 앞서... \n",
        "\n",
        "Menu -> Runtime -> Change runtime type "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYy0UfRvFtyJ",
        "colab_type": "text"
      },
      "source": [
        "![gpu setting](https://raw.githubusercontent.com/mi2rl/datasets/master/gpu.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibuA8-46ydR6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROKfeR4sB_38",
        "colab_type": "text"
      },
      "source": [
        "# 1. 데이터 준비: MedNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhbWZItrGoeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 다운로드\n",
        "!wget https://raw.githubusercontent.com/mi2rl/datasets/master/mednist.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm07t8jnHFcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 압축 풀기\n",
        "!tar xzf mednist.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMQbFRjVHFfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 패키지 불러오기\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import cv2\n",
        "import time\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H4_fQZNHFh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataDir = 'resized'               # 데이터 위치\n",
        "classNames = sorted(os.listdir(dataDir))  # 각 클래스의 이름들\n",
        "numClass = len(classNames)        # Number of classes = number of subdirectories\n",
        "imageFiles = [[os.path.join(dataDir,classNames[i],x) for x in os.listdir(os.path.join(dataDir,classNames[i]))]\n",
        "              for i in range(numClass)]                     # 각 클래스 별 파일 이름들\n",
        "numEach = [len(imageFiles[i]) for i in range(numClass)]     # 각 클래스 별 파일 갯수\n",
        "imageFilesList = []               # 모든 파일이름\n",
        "imageClass = []                   # 각각의 파일들에 대한 클래스 \n",
        "\n",
        "for i in range(numClass):\n",
        "    imageFilesList.extend(imageFiles[i])\n",
        "    imageClass.extend([i]*numEach[i])\n",
        "    \n",
        "numTotal = len(imageClass)        # 전체 파일 갯수\n",
        "imageWidth, imageHeight = Image.open(imageFilesList[0]).size         # 각 영상의 사이즈(width, height)\n",
        "\n",
        "print(\"There are\",numTotal,\"images in\",numClass,\"distinct categories\")\n",
        "print(\"Label names:\",classNames)\n",
        "print(\"Label counts:\",numEach)\n",
        "print(\"Image dimensions:\",imageWidth,\"x\",imageHeight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrxbvSerHFki",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 전체 이미지 중 9개를 랜덤으로 골라 3x3으로 레이블과 함께 그리기\n",
        "# -- 여러번 실행하며 이미지들을 살펴보세요 --\n",
        "\n",
        "plt.subplots(3,3,figsize=(8,8))\n",
        "for i,k in enumerate(np.random.randint(numTotal, size=9)): \n",
        "    im = Image.open(imageFilesList[k])                      \n",
        "    arr = np.array(im)\n",
        "    plt.subplot(3,3,i+1)\n",
        "    plt.xlabel(classNames[imageClass[k]])\n",
        "    plt.imshow(arr,cmap='gray',vmin=0,vmax=255)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXOTdcrs4QVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이미지 리스트 살펴보기\n",
        "imageFilesList[0:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc7wMIt4FiB_",
        "colab_type": "text"
      },
      "source": [
        "# 2. VGG16를 이용한 분류 실습 (w/ ImageNet pre-trained weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9pA19KsFZHG",
        "colab_type": "text"
      },
      "source": [
        "![VGG16 네트워크 구조](https://www.cs.toronto.edu/~frossard/post/vgg16/vgg16.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42X_EccV9fgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import Input, Conv2D, MaxPool2D, Dense, Flatten, Activation\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQydjH4l9tAG",
        "colab_type": "text"
      },
      "source": [
        "# 2.1. [Quiz] 순서가 섞인 layer들을 VGG16 구성에 맞게 배치해보세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQCGxNBH9G09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = Input(shape=(224, 224, 3,), name=\"VGGInput\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHfkHQba-T_W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
        "x = Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
        "x = Conv2D(filters=256, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
        "x = MaxPool2D(padding='same')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMjc4HcX-UCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
        "x = Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
        "x = Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
        "x = MaxPool2D(padding='same')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnFNuXG6-ePI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Conv2D(filters=4096, kernel_size=(7,7), padding='valid', activation='relu')(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(4096, activation='relu')(x)\n",
        "pred = Dense(1000, activation='softmax')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkjP3szO-T8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
        "x = Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
        "x = MaxPool2D(padding='same')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIutE6mo-Mez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
        "x = Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
        "x = Conv2D(filters=512, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
        "x = MaxPool2D(padding='same')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6HvoFRi-T5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu')(inputs)\n",
        "x = Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu')(x)\n",
        "x = MaxPool2D(padding='same')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO5AiwPf-MiN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=inputs, outputs=pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhErtRaK9pfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ikL97iT9ph3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = Adam(lr=1e-03)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H00490Rz9pk8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8grXT5RWAR7W",
        "colab_type": "text"
      },
      "source": [
        "# 2.2. VGG16 모델 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_KUJrPaAiSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications import vgg16\n",
        "\n",
        "# VGG16 모델 불러오기\n",
        "model = vgg16.VGG16()\n",
        "\n",
        "# 모델의 모양을 보여준다.\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_UFP5cCJKuk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model 구성도 plot\n",
        "from IPython.display import Image\n",
        "\n",
        "keras.utils.plot_model(model, to_file='vgg16.png', show_shapes=True, show_layer_names=True)\n",
        "Image(filename='vgg16.png')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oe8WYVBEh4K",
        "colab_type": "text"
      },
      "source": [
        "**VGG16**\n",
        "\n",
        "`keras.applications.vgg16.VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)`\n",
        "\n",
        "\n",
        "VGG16 model, with weights pre-trained on ImageNet.\n",
        "\n",
        "This model can be built both with 'channels_first' data format (channels, height, width) or 'channels_last' data format (height, width, channels).\n",
        "\n",
        "The default input size for this model is 224x224.\n",
        "\n",
        "**Arguments**\n",
        "\n",
        "\n",
        "\n",
        "*   include_top: whether to include the 3 fully-connected layers at the top of the network.\n",
        "*   weights: one of None (random initialization) or 'imagenet' (pre-training on ImageNet).\n",
        "*   input_tensor: optional Keras tensor (i.e. output of layers.Input()) to use as image input for the model.\n",
        "*   input_shape: optional shape tuple, only to be specified if include_top is False (otherwise the input shape has to be (224, 224, 3) (with 'channels_last' data format) or (3, 224, 224) (with 'channels_first' data format). It should have exactly 3 inputs channels, and width and height should be no smaller than 32. E.g. (200, 200, 3) would be one valid value.\n",
        "*   pooling: Optional pooling mode for feature extraction when include_top is False.\n",
        "*   classes: optional number of classes to classify images into, only to be specified if include_top is  True, and if no weights argument is specified."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmJOZlNSC30k",
        "colab_type": "text"
      },
      "source": [
        "# keras 에서 제공되는 모델들 참고: https://keras.io/applications/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hpF46233PXn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VGG16 모델을 이용해 prediction 하는 함수\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from IPython.display import display # 이미지 출력 함수\n",
        "\n",
        "def predict_vgg16(model, filename) :\n",
        "    # 이미지 파일을 읽고 화면에 표시\n",
        "    image = load_img(filename)\n",
        "    display(image)\n",
        "\n",
        "    # 모델 사이즈로 이미지 파일을 읽기\n",
        "    image = load_img(filename, target_size=(224, 224))\n",
        "\n",
        "    # 이미지 데이터를 numpy로 변환\n",
        "    image = img_to_array(image)\n",
        "\n",
        "    # vgg16.preprocess_input()을 호출하기 위해 차원을 조정\n",
        "    # 보통 모델을 여러 이미지를 한번에 호출. \n",
        "    # 맨 앞의 1 : 이미지 갯수가 1개라는 것.\n",
        "    # 두번째 224 : 가로\n",
        "    # 세번째 224 : 세로\n",
        "    # 네번째 3 : R, G, B 3개\n",
        "    image = image.reshape((1, 224, 224, 3))\n",
        "\n",
        "    # VGG16 모델 호출을 위해 데이터 전처리.\n",
        "    # -255 ~ 255 사이 값으로 정규화한다.\n",
        "    # 그리고 RGB를 BGR순으로 바꾼다.\n",
        "    image = vgg16.preprocess_input(image)\n",
        "\n",
        "\n",
        "    # 이미지를 모델에 적용\n",
        "    yhat = model.predict(image)\n",
        "\n",
        "    # 모델 적용된 결과를 파싱\n",
        "    label = vgg16.decode_predictions(yhat)\n",
        "\n",
        "    # 가장 확률이 높은 결과를 획득\n",
        "    label = label[0][0]\n",
        "\n",
        "    # 라벨과 라벨을 예측한 확률을 출력\n",
        "    print('%s (%.2f%%)' % (label[1], label[2]*100))    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owkpMH9i3Ph8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files = imageFilesList[0:10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXZ7oCZ13Pkf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for file in files:\n",
        "  predict_vgg16(model, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWjJxcdDF_Bi",
        "colab_type": "text"
      },
      "source": [
        "# 2.3. Dataset 나누기: Train / Validation / Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXKqQ0ig61ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "validFrac = 0.2   # Define the fraction of images to move to validation dataset\n",
        "testFrac = 0.2    # Define the fraction of images to move to test dataset\n",
        "validList = []\n",
        "testList = []\n",
        "trainList = []\n",
        "\n",
        "for i in range(numTotal):\n",
        "    rann = np.random.random() # Randomly reassign images\n",
        "    if rann < validFrac:\n",
        "        validList.append(i)\n",
        "    elif rann < testFrac + validFrac:\n",
        "        testList.append(i)\n",
        "    else:\n",
        "        trainList.append(i)\n",
        "        \n",
        "nTrain = len(trainList)  # Count the number in each set\n",
        "nValid = len(validList)\n",
        "nTest = len(testList)\n",
        "print(\"Training images =\",nTrain,\"Validation =\",nValid,\"Testing =\",nTest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QWKb_Aw69us",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ./train\n",
        "!mkdir ./valid\n",
        "!mkdir ./test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQh-O9Ai9IUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "for i in tqdm(range(len(trainList))):\n",
        "  root, clas, src = imageFilesList[trainList[i]].split('/')\n",
        "  dest = os.path.join('./train',clas,src)\n",
        "  if not os.path.exists(os.path.join('./train',clas)):\n",
        "    os.mkdir(os.path.join('./train',clas))\n",
        "  shutil.copy(imageFilesList[trainList[i]], dest)\n",
        "  \n",
        "for i in tqdm(range(len(validList))):\n",
        "  root, clas, src = imageFilesList[validList[i]].split('/')\n",
        "  dest = os.path.join('./valid',clas,src)\n",
        "  if not os.path.exists(os.path.join('./valid',clas)):\n",
        "    os.mkdir(os.path.join('./valid',clas))\n",
        "  shutil.copy(imageFilesList[validList[i]], dest)\n",
        "  \n",
        "    \n",
        "for i in tqdm(range(len(testList))):\n",
        "  root, clas, src = imageFilesList[testList[i]].split('/')\n",
        "  dest = os.path.join('./test',clas,src)\n",
        "  if not os.path.exists(os.path.join('./test',clas)):\n",
        "    os.mkdir(os.path.join('./test',clas))\n",
        "  shutil.copy(imageFilesList[testList[i]], dest)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OALwHXmrGPIO",
        "colab_type": "text"
      },
      "source": [
        "# 2.4. Image Data Generator 정의 (+Data Augmentation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0nM9C_i0cLY",
        "colab_type": "text"
      },
      "source": [
        "**Keras API - ImageDataGenerator: 일정한 규칙으로 만들어진 폴더구조에서 데이터셋을 자동으로 불러와 학습에 사용할 수 있게 도와주는 API**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5qeh9IL0YHe",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://miro.medium.com/max/875/1*HpvpA9pBJXKxaPCl5tKnLg.jpeg)\n",
        "https://medium.com/@vijayabhaskar96/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmRof3T-0w-Z",
        "colab_type": "text"
      },
      "source": [
        "**Data augmentation: 데이터에 다양한 형태의 변화를 임의로 생성하여 데이터의 갯수와 다양성을 증가시키는 방법**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wUAsi6pz58M",
        "colab_type": "text"
      },
      "source": [
        "![Data augmentation](https://miro.medium.com/max/1250/1*rvwzKkvhlDN3Wo_4Oay_4Q.png)\n",
        "https://medium.com/@thimblot/data-augmentation-boost-your-image-dataset-with-few-lines-of-python-155c2dc1baec\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzlyOZr-4xqw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "def preprocess_input_vgg(x):\n",
        "    X = np.expand_dims(x, axis=0)\n",
        "    X = preprocess_input(X)\n",
        "    return X[0]\n",
        "\n",
        "\n",
        "train_dir = './train'\n",
        "validation_dir = './valid'\n",
        "test_dir = './test'\n",
        "batch_size = 32\n",
        "image_size = 224\n",
        "\n",
        "# 학습에 사용될 이미지 데이터 생성기\n",
        "train_datagen = ImageDataGenerator(\n",
        "      preprocessing_function=preprocess_input_vgg,\n",
        "      rotation_range=180, # 회전 최대 20도\n",
        "      width_shift_range=0.2, # 좌우 이동\n",
        "      height_shift_range=0.2, # 상하 이동\n",
        "      horizontal_flip=True, # 좌우 반전\n",
        "      vertical_flip=True, # 상하 반전\n",
        "      )\n",
        " \n",
        "# 검증에 사용될 이미지 데이터 생성기\n",
        "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg)\n",
        "\n",
        "# 테스트에 사용될 이미지 데이터 생성기\n",
        "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input_vgg)\n",
        "\n",
        "\n",
        "# 학습에 사용될 데이터 생성기  \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_dir,\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True)\n",
        "\n",
        "# 검증에 사용될 데이터 생성기\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)\n",
        "\n",
        "# 테스트에 사용될 데이터 생성기\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=1,\n",
        "        class_mode='categorical',\n",
        "        shuffle=False)\n",
        "\n",
        "class_num=len(train_generator.class_indices)\n",
        "\n",
        "custom_labels = list(validation_generator.class_indices.keys())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59xxKdQ24xtk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras.models import Model\n",
        "from keras import models\n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras.applications import VGG16\n",
        "import keras.backend as K\n",
        "\n",
        "K.clear_session() # 새로운 세션으로 시작"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Omc81vxOlww",
        "colab_type": "text"
      },
      "source": [
        "# 2.5. VGG16 as a Feature Extractor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is4jiyR35ozW",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://miro.medium.com/max/875/1*W91k18rRAZfJnsM8bhUDXA.png)\n",
        "https://towardsdatascience.com/a-comprehensive-hands-on-guide-to-transfer-learning-with-real-world-applications-in-deep-learning-212bf3b2f27a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZJLsoWNHIaE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 불러오기\n",
        "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(image_size, image_size, 3))\n",
        "vgg_model.summary()\n",
        "\n",
        "# Convolution Layer를 학습되지 않도록 고정 \n",
        "for layer in vgg_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvV31g1IGmu1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 새로운 모델 생성하기\n",
        "last = vgg_model.output\n",
        " \n",
        "# VGG16모델에 Fully Connected부분을 재구성해서 추가\n",
        "x = Flatten()(last)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "pred = Dense(class_num, activation='softmax')(x)\n",
        "\n",
        "model = Model(vgg_model.input, pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpvmrwYPGm8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 새로운 모델 요약\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHHjLfRGGm_0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 새로운 모델 저장\n",
        "vgg16_model_path = 'vgg16_finetuning.h5'\n",
        "\n",
        "model.save(vgg16_model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0XDfcreHdsY",
        "colab_type": "text"
      },
      "source": [
        "# 2.6. 새로운 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wEl365N4xwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "# 모델 로딩\n",
        "model = load_model(vgg16_model_path)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100 ,\n",
        "      epochs=2,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
        "      verbose=1)\n",
        " \n",
        "# 모델 저장\n",
        "model.save(vgg16_model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BicDThpJMjYe",
        "colab_type": "text"
      },
      "source": [
        "# 2.7. 학습 결과 시각화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APTOYXtQKmHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['acc']\n",
        "loss = history.history['loss']\n",
        "valacc = history.history['val_acc']\n",
        "valloss = history.history['val_loss']\n",
        "\n",
        "\n",
        "epochs = range(len(acc))\n",
        " \n",
        "plt.plot(epochs, acc, 'b', label='accuracy')\n",
        "plt.plot(epochs, loss, 'r', label='loss')\n",
        "plt.plot(epochs, valacc, 'b--', label='val_accuracy')\n",
        "plt.plot(epochs, valloss, 'r--', label='val_loss')\n",
        "plt.title('accuracy and loss')\n",
        "plt.legend()\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8LkTxYwMhVr",
        "colab_type": "text"
      },
      "source": [
        "# 2.8. 학습된 모델을 이용해 Test 데이터에 대한 Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ifa-qfYCU25r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate_generator(test_generator, steps=test_generator.samples, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmV0OYqXNa9A",
        "colab_type": "text"
      },
      "source": [
        "# 3. VGG16를 이용한 분류 실습 (from Scratch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T46Avh8YNsOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 불러오기\n",
        "vgg_model = VGG16(weights=None, include_top=False, input_shape=(image_size, image_size, 3))\n",
        "vgg_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67k4voNSwEOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "last = vgg_model.output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTvTMNkUNsLy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VGG16모델에 Fully Connected부분을 재구성해서 추가\n",
        "x = Flatten()(last)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "pred = Dense(class_num, activation='softmax')(x)\n",
        "\n",
        "model = Model(vgg_model.input, pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuYjR4LVNsJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 새로운 모델 요약\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OObH3RkkNsGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 새로운 모델 저장\n",
        "vgg16_model_path = 'vgg16_scratch.h5'\n",
        "\n",
        "model.save(vgg16_model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSh_mDgUNsDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 로딩\n",
        "model = load_model(vgg16_model_path)\n",
        "\n",
        "# 모델 컴파일\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=100 ,\n",
        "      epochs=2,\n",
        "      validation_data=validation_generator,\n",
        "      validation_steps=validation_generator.samples/validation_generator.batch_size,\n",
        "      verbose=1)\n",
        "\n",
        "# 모델 저장\n",
        "model.save(vgg16_model_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNhECKJ0NsBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = history.history['acc']\n",
        "loss = history.history['loss']\n",
        "valacc = history.history['val_acc']\n",
        "valloss = history.history['val_loss']\n",
        "\n",
        "\n",
        "epochs = range(len(acc))\n",
        " \n",
        "plt.plot(epochs, acc, 'b', label='accuracy')\n",
        "plt.plot(epochs, loss, 'r', label='loss')\n",
        "plt.plot(epochs, valacc, 'b--', label='val_accuracy')\n",
        "plt.plot(epochs, valloss, 'r--', label='val_loss')\n",
        "plt.title('accuracy and loss')\n",
        "plt.legend()\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qx1eDAy0IFST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For prediction purposes\n",
        "y_pred = model.predict_generator(test_generator, steps=test_generator.samples, verbose=1)\n",
        "y_pred1 = np.argmax(y_pred, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPt7DlIsUw6U",
        "colab_type": "text"
      },
      "source": [
        "# 4. Confusion Matrix Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-P5meT9WN9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj370N6rU2jN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# y_test labeling\n",
        "y_test = test_generator.labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhqlquNIU2gc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# calculate confusion matrix for the predicted dataset\n",
        "cm = confusion_matrix(y_test, y_pred1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR90a3Fiaibu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make a dataframe using cm array\n",
        "df_cm = pd.DataFrame(cm, index = [i for i in classNames], columns = [i for i in classNames])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQzfqDSNaiZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot confusion matrix\n",
        "plt.figure(figsize = (10, 7))\n",
        "sn.heatmap(df_cm, annot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h5U1n_EaiW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# classification report generation: precision, recall, f1-score. \n",
        "print(classification_report(y_test, y_pred1, target_names=classNames))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBlHqWhCM9gL",
        "colab_type": "text"
      },
      "source": [
        "# 5. VGG16 + GradCAM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8aLprq3y4mh",
        "colab_type": "text"
      },
      "source": [
        "![gradCAM](https://camo.githubusercontent.com/450498bd998fd99d51b647d2b6c8631e94585522/687474703a2f2f692e696d6775722e636f6d2f4a614762645a352e706e67)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fb96qSvky9jM",
        "colab_type": "text"
      },
      "source": [
        "**Grad-CAM: Why did you say that? Visual Explanations from Deep Networks via Gradient-based Localization**\n",
        "Ramprasaath R. Selvaraju, Abhishek Das, Ramakrishna Vedantam, Michael Cogswell, Devi Parikh, Dhruv Batra\n",
        "https://arxiv.org/abs/1610.02391"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sLMeFLDzVAD",
        "colab_type": "text"
      },
      "source": [
        "**Example: 'Boxer'**\n",
        "\n",
        "![alt text](https://github.com/PowerOfCreation/keras-grad-cam/raw/master/examples/cat_dog.png) \n",
        "![alt text](https://github.com/PowerOfCreation/keras-grad-cam/raw/master/examples/cat_dog_242_gradcam.jpg)\n",
        "![alt text](https://github.com/PowerOfCreation/keras-grad-cam/raw/master/examples/cat_dog_242_guided_gradcam.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8waiUN2R6l0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def grad_cam(input_model, image):\n",
        "    nb_classes = 6  # 클래스 숫자\n",
        "    \n",
        "    preds = input_model.predict(image)\n",
        "    predicted_label = np.argmax(preds[0])\n",
        "    \n",
        "    output = input_model.output[:,predicted_label]  # 예측 벡터에서 해당 클래스 항목\n",
        "    last_conv_layer = input_model.get_layer('block5_conv3') # VGG16의 마지막 convolution layer의 특성 맵\n",
        "    \n",
        "    grads = K.gradients(output, last_conv_layer.output)[0] # 'block5_conv3'의 특성 맵 출력에 대한 해당 클래스의 그래디언트\n",
        "    pooled_grads = K.mean(grads, axis=(0, 1, 2)) # 특성 맵 채널별 그래디언트 평균값이 담긴 (512,) 크기의 벡터\n",
        "    \n",
        "    iterate = K.function([model.input],[pooled_grads, last_conv_layer.output[0]]) # query 이미지에 대해 pooled_grads 와 'block5_conv3'의 특성 맵 출력을 구함\n",
        "    pooled_grads_value, conv_layer_output_value = iterate([image]) # query 영상을 넣고 2개의 배열을 얻음\n",
        "    \n",
        "    for i in range(512):                                            # 해당 클래스에 대한 채널의 중요도를 특성 맵 배열의 채널에 곱함\n",
        "        conv_layer_output_value[:,:,i] *= pooled_grads_value[i]\n",
        "        \n",
        "    heatmap = np.mean(conv_layer_output_value, axis=-1)   # 만들어진 특성 맵에서 채널 축을 따라 평균 --> 해당 클래스의 히트맵\n",
        "    \n",
        "    # 히트맵 후처리\n",
        "    heatmap = np.maximum(heatmap, 0)               \n",
        "    heatmap /= np.max(heatmap)\n",
        "    heatmap = cv2.resize(heatmap, (224, 224))\n",
        "\n",
        "    # 입력 영상을 8-bit RGB 영상으로 변환\n",
        "    image = image[0, :]\n",
        "    image -= np.min(image)\n",
        "    image = np.minimum(image, 255)\n",
        "\n",
        "    cam = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
        "    cam = np.float32(cam) + np.float32(image)\n",
        "    cam = 255 * cam / np.max(cam)\n",
        "    \n",
        "    return np.uint8(cam), heatmap, predicted_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMdHEUKXUXqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select a random query image\n",
        "inum = random.randrange(0,len(imageFilesList))\n",
        "qimage0 = load_img(imageFilesList[inum], target_size=(224, 224))\n",
        "qimage  = img_to_array(qimage0)\n",
        "qimage  = qimage.reshape((1, 224, 224, 3))\n",
        "qimage  = vgg16.preprocess_input(qimage)\n",
        "\n",
        "# CAM 출력\n",
        "cam, heatmap, plabel = grad_cam(model, qimage)\n",
        "plt.title('T:'+classNames[imageClass[inum]]+', P:'+classNames[plabel])\n",
        "plt.imshow(cam)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob1JaNc1UcCf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
