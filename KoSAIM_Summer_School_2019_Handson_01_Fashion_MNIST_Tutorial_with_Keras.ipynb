{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Fashion-MNIST_tutorial_with_Keras.ipynb의 사본의 사본의 사본","version":"0.3.2","provenance":[{"file_id":"https://github.com/mi2rl/ai_handson/blob/master/KoSAIM_Summer_School_2019_Handson_01_Fashion_MNIST_Tutorial_with_Keras.ipynb","timestamp":1566791743000},{"file_id":"https://github.com/mi2rl/ai_handson/blob/master/KoSAIM_Summer_School_2019_Handson_01_Fashion_MNIST_Tutorial_with_Keras.ipynb","timestamp":1566526324457},{"file_id":"https://github.com/mi2rl/ai_handson/blob/master/KoSAIM_Summer_School_2019_Handson_01_Fashion_MNIST_Tutorial.ipynb","timestamp":1566476677527}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"WsAx4toWxKZE","colab_type":"text"},"source":["![대체 텍스트](https://www.pyimagesearch.com/wp-content/uploads/2019/02/fashion_mnist_dataset_sample.png)"]},{"cell_type":"markdown","metadata":{"id":"xhfmxR8o2sWd","colab_type":"text"},"source":["\n","# MNIST is too easy.\n","Convolutional nets can achieve 99.7% on MNIST. Classic machine learning algorithms can also achieve 97% easily. \n","# MNIST is overused. \n","In this April 2017 Twitter thread, Google Brain research scientist and deep learning expert Ian Goodfellow calls for people to move away from MNIST.\n","# MNIST can not represent modern CV tasks.\n","\n","# Fashion MNIST dataset\n","Similar to the MNIST digit dataset, the Fashion MNIST dataset includes:\n","\n","60,000 training examples\n","\n","10,000 testing examples\n","\n","10 classes\n","\n","28×28 grayscale/single channel images"]},{"cell_type":"markdown","metadata":{"id":"sFD7RLgA3ouu","colab_type":"text"},"source":["![대체 텍스트](https://www.pyimagesearch.com/wp-content/uploads/2019/02/fashion_mnist_obtaining.jpg)"]},{"cell_type":"code","metadata":{"id":"OFK9236vMmZO","colab_type":"code","colab":{}},"source":["import numpy as np\n","from keras.utils import np_utils\n","\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Flatten\n","from keras.layers import Activation\n","from keras.layers.convolutional import Conv2D\n","from keras.layers.convolutional import MaxPooling2D\n","from keras.layers.normalization import BatchNormalization\n","\n","from keras import optimizers\n","\n","from keras import backend as K\n","K.set_image_dim_ordering('tf')\n","\n","%matplotlib inline\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"emDMGh2lWBHd","colab_type":"text"},"source":["#STEP 1: Fashion MNIST 데이터 읽어들이기"]},{"cell_type":"code","metadata":{"id":"1gjzm6goU1rp","colab_type":"code","colab":{}},"source":["from keras.datasets import fashion_mnist\n","((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n","\n","# initialize the label names\n","labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\", \n","             \"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8RwCuia7X_gD","colab_type":"text"},"source":["#STEP 2: 데이터 살펴보기"]},{"cell_type":"code","metadata":{"id":"YFgKtGe4YFoT","colab_type":"code","colab":{}},"source":["plt_row = 5\n","plt_col = 5\n","\n","width = height = 28\n","\n","plt.rcParams[\"figure.figsize\"] = (15,15)\n","\n","f, axarr = plt.subplots(plt_row, plt_col)\n","\n","for i in range(plt_row*plt_col):\n","\n","    sub_plt = axarr[int(i/plt_row), i%plt_col]\n","    sub_plt.axis('off')\n","    sub_plt.imshow(testX[i].reshape(width, height), cmap='gray')\n","    sub_plt_title = 'R: ' + labelNames[testY[i]]\n","    sub_plt.set_title(sub_plt_title)\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aPIIgjLbc9Cu","colab_type":"text"},"source":["#STEP 3: 딥러닝을 위한 데이터 전처리"]},{"cell_type":"code","metadata":{"id":"q9Lx0-DQdD93","colab_type":"code","colab":{}},"source":["# flatten 28*28 images to a 784 vector for each image\n","width = height = 28\n","num_pixels = width * height\n","trainX = trainX.reshape(60000, num_pixels).astype('float32') / 255.0\n","testX = testX.reshape(10000, num_pixels).astype('float32') / 255.0\n","\n","# 훈련셋과 검증셋 분리\n","valX = trainX[50000:]\n","valY = trainY[50000:]\n","trainX = trainX[:50000]\n","trainY = trainY[:50000]\n","\n","# one hot encode outputs\n","num_classes = 10\n","trainY = np_utils.to_categorical(trainY, num_classes)\n","valY = np_utils.to_categorical(valY, num_classes)\n","testY = np_utils.to_categorical(testY, num_classes)\n","\n","print ('train shape: \\t', trainX.shape)\n","print ('valid shape: \\t', valX.shape)\n","print ('test shape: \\t', testX.shape)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wtemFso_KR6o","colab_type":"code","colab":{}},"source":["trainX.shape"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6BhD2uuPfgZG","colab_type":"text"},"source":["#STEP 4: 첫번째 인공지능 모델 (퍼셉트론)\n","\n","![대체 텍스트](https://www.simplilearn.com/ice9/free_resources_article_thumb/diagram-of-a-biological-neuron.jpg)\n","\n","![대체 텍스트](http://bit.ly/2ldH0Bg)"]},{"cell_type":"code","metadata":{"id":"H-P5NCZHfxNs","colab_type":"code","colab":{}},"source":["def logistic_regression_model():\n","    # create model\n","    model = Sequential()\n","    \n","    model.add(Dense(num_classes, input_dim=num_pixels, kernel_initializer='normal', activation='softmax'))\n","    \n","    # compile model\n","    sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DVwdrbt2gyWg","colab_type":"text"},"source":["#STEP 5: 첫번째 인공지능 모델 학습!!!"]},{"cell_type":"code","metadata":{"id":"gCgT7q9dgx6C","colab_type":"code","colab":{}},"source":["# build the model\n","model = logistic_regression_model()\n","model.summary()\n","# fix random seed for reproductibility\n","seed = 7\n","np.random.seed(seed)\n","\n","# FIT THE MODEL - OPTIMIZATION\n","hist = model.fit(trainX, trainY, validation_data=(valX, valY), epochs=20, batch_size=64, verbose=2)\n","model.save('logistic_regression_model.h5')\n","\n","# 학습과정 살펴보기\n","fig, loss_ax = plt.subplots()\n","\n","acc_ax = loss_ax.twinx()\n","\n","loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n","loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n","loss_ax.set_ylim([0.0, 1.5])\n","\n","acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n","acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n","acc_ax.set_ylim([0.5, 1.0])\n","\n","loss_ax.set_xlabel('epoch')\n","loss_ax.set_ylabel('loss')\n","acc_ax.set_ylabel('accuray')\n","\n","loss_ax.legend(loc='upper left')\n","acc_ax.legend(loc='lower left')\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J_i3PjlRjRSY","colab_type":"text"},"source":["#STEP 6: 결과 확인 (테스트 데이터셋)"]},{"cell_type":"code","metadata":{"id":"Y2YqfegLFobt","colab_type":"code","colab":{}},"source":["# Final evaluation of the model\n","scores = model.evaluate(testX, testY, verbose=0)\n","print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P9pKn3KijmbK","colab_type":"text"},"source":["#STEP 7: 학습된 weight 살펴보기"]},{"cell_type":"code","metadata":{"id":"FmTwHrdQFobw","colab_type":"code","colab":{}},"source":["# Visualize weights\n","W = model.layers[0].get_weights()[0]\n","print(\"W shape : \", W.shape)\n","\n","W = np.transpose(W, (1,0))\n","\n","plt.figure(figsize=(15, 15), frameon=False)\n","for ind, val in enumerate(W):\n","    plt.subplot(5, 5, ind + 1)\n","    im = val.reshape((28,28))\n","    plt.axis(\"off\")\n","    plt.imshow(im, cmap='gray',interpolation='nearest')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kuYHyuZvDS24","colab_type":"code","colab":{}},"source":["model.layers[0].get_weights()[0].shape"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hlxVSWn8kKXH","colab_type":"text"},"source":["![대체 텍스트](https://www.pyimagesearch.com/wp-content/uploads/2019/02/fashion_mnist_obtaining.jpg)"]},{"cell_type":"markdown","metadata":{"id":"q-E36CT-koWF","colab_type":"text"},"source":["#STEP 8: 두번째 인공지능 모델 (MLP)\n","\n","![대체 텍스트](https://www.researchgate.net/profile/Hadley_Brooks/publication/270274130/figure/fig3/AS:667886670594050@1536247999230/Architecture-of-a-multilayer-neural-network-with-one-hidden-layer-The-input-layer.png)"]},{"cell_type":"code","metadata":{"id":"OCxtcC-TkjGo","colab_type":"code","colab":{}},"source":["def multi_linear_perceptron_model():\n","    # create model\n","    model = Sequential()\n","    \n","    model.add(Dense(256, input_dim=num_pixels, kernel_initializer='normal', activation='sigmoid'))\n","    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n","    \n","    # compile model\n","    sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ApdIJBsjFob1","colab_type":"code","colab":{}},"source":["# build the model\n","model = multi_linear_perceptron_model()\n","model.summary()\n","\n","# fix random seed for reproductibility\n","seed = 7\n","np.random.seed(seed)\n","\n","# Fit the model\n","hist = model.fit(trainX, trainY, validation_data=(valX, valY), epochs=20, batch_size=64, verbose=2)\n","model.save('multi_linear_perceptron_model.h5')\n","\n","# 5. 학습과정 살펴보기\n","fig, loss_ax = plt.subplots()\n","\n","acc_ax = loss_ax.twinx()\n","\n","loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n","loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n","loss_ax.set_ylim([0.0, 1.5])\n","\n","acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n","acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n","acc_ax.set_ylim([0.5, 1.0])\n","\n","loss_ax.set_xlabel('epoch')\n","loss_ax.set_ylabel('loss')\n","acc_ax.set_ylabel('accuray')\n","\n","loss_ax.legend(loc='upper left')\n","acc_ax.legend(loc='lower left')\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dSEjknxsFob4","colab_type":"code","colab":{}},"source":["# Final evaluation of the model\n","scores = model.evaluate(testX, testY, verbose=0)\n","print(\"Error: %.2f%%\" % (100-scores[1]*100))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eLQtffyil8WK","colab_type":"text"},"source":["#STEP 9: 세번째 인공지능 모델 (DEEP-MLP)\n","\n","![대체 텍스트](https://i.stack.imgur.com/OH3gI.png)"]},{"cell_type":"markdown","metadata":{"id":"26LDMwE1InL2","colab_type":"text"},"source":["![대체 텍스트](http://www.saedsayad.com/images/ANN_Sigmoid.png)"]},{"cell_type":"code","metadata":{"id":"rrRqJK2KFob8","colab_type":"code","colab":{}},"source":["def deep_perceptron_initial_model():\n","    # create model\n","    model = Sequential()\n","    \n","    model.add(Dense(256, input_dim=num_pixels, kernel_initializer='normal', activation='sigmoid'))\n","    model.add(Dense(256, kernel_initializer='normal', activation='sigmoid'))\n","    model.add(Dense(256, kernel_initializer='normal', activation='sigmoid'))\n","    model.add(Dense(256, kernel_initializer='normal', activation='sigmoid')) \n","    model.add(Dense(256, kernel_initializer='normal', activation='sigmoid'))\n","    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n","    \n","    # compile model\n","    sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3SIj7p4dFob_","colab_type":"code","colab":{}},"source":["# build the model\n","model = deep_perceptron_initial_model()\n","model.summary()\n","\n","# fix random seed for reproductibility\n","seed = 7\n","np.random.seed(seed)\n","\n","# Fit the model\n","hist = model.fit(trainX, trainY, validation_data=(valX, valY), epochs=20, batch_size=64, verbose=2)\n","model.save('deep_perceptron_initial_model.h5')\n","\n","# 5. 학습과정 살펴보기\n","fig, loss_ax = plt.subplots()\n","\n","acc_ax = loss_ax.twinx()\n","\n","loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n","loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n","\n","acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n","acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n","\n","loss_ax.set_xlabel('epoch')\n","loss_ax.set_ylabel('loss')\n","acc_ax.set_ylabel('accuray')\n","\n","loss_ax.legend(loc='upper left')\n","acc_ax.legend(loc='lower left')\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dTTj4GeCJ8K2","colab_type":"code","colab":{}},"source":["# Final evaluation of the model\n","scores = model.evaluate(testX, testY, verbose=0)\n","print(\"Error: %.2f%%\" % (100-scores[1]*100))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WYfMo7tFnBed","colab_type":"text"},"source":["#STEP 10: 세번째 인공지능 모델의 문제점과 개선"]},{"cell_type":"markdown","metadata":{"id":"sOdXlYa0YFTZ","colab_type":"text"},"source":["![대체 텍스트](https://image.slidesharecdn.com/usuconference-deeplearning-160418191119/95/introduction-to-deep-learning-7-638.jpg?cb=1461006739)"]},{"cell_type":"markdown","metadata":{"id":"BDmw6R8_GNed","colab_type":"text"},"source":["![대체 텍스트](https://smartstuartkim.files.wordpress.com/2019/02/vanishinggradient-1.png?w=1140&h=492)"]},{"cell_type":"code","metadata":{"id":"LGPy6P2zFocH","colab_type":"code","colab":{}},"source":["#  Hint\n","# 'relu'\n","\n","def deep_perceptron_model_with_relu():\n","    # create model\n","    model = Sequential()\n","    \n","    model.add(Dense(256, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n","    model.add(Dense(256, kernel_initializer='normal', activation='????'))\n","    model.add(Dense(256, kernel_initializer='normal', activation='????'))\n","    model.add(Dense(256, kernel_initializer='normal', activation='????'))\n","    model.add(Dense(256, kernel_initializer='normal', activation='????'))    \n","    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n","    # compile model\n","    \n","    sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uVgGp42FFocM","colab_type":"code","colab":{}},"source":["# build the model\n","model = deep_perceptron_model_with_relu()\n","model.summary()\n","\n","# fix random seed for reproductibility\n","seed = 7\n","np.random.seed(seed)\n","\n","# Fit the model\n","hist = model.fit(trainX, trainY, validation_data=(valX, valY), epochs=20, batch_size=64, verbose=2)\n","model.save('deep_perceptron_model_with_dropout.h5')\n","\n","# 5. 학습과정 살펴보기\n","fig, loss_ax = plt.subplots()\n","\n","acc_ax = loss_ax.twinx()\n","\n","loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n","loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n","loss_ax.set_ylim([0.0, 1.5])\n","\n","acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n","acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n","acc_ax.set_ylim([0.5, 1.0])\n","\n","loss_ax.set_xlabel('epoch')\n","loss_ax.set_ylabel('loss')\n","acc_ax.set_ylabel('accuray')\n","\n","loss_ax.legend(loc='upper left')\n","acc_ax.legend(loc='lower left')\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cC6n5edlFocR","colab_type":"code","colab":{}},"source":["# Final evaluation of the model\n","scores = model.evaluate(testX, testY, verbose=0)\n","print(\"Perceptron model with relu error: %.2f%%\" % (100-scores[1]*100))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LLTnR7uKJm5m","colab_type":"text"},"source":["![대체 텍스트](https://miro.medium.com/max/1200/1*iWQzxhVlvadk6VAJjsgXgg.png)"]},{"cell_type":"code","metadata":{"id":"SWmvv-noJuQ-","colab_type":"code","colab":{}},"source":["#  Hint\n","from keras.layers import Dropout\n","\n","def deep_perceptron_model_with_relu_dropout():\n","    # create model\n","    model = Sequential()\n","    model.add(Dense(256, input_dim=num_pixels, kernel_initializer='normal', activation='relu'))\n","    model.add(????(0.2))\n","    \n","    model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n","    model.add(????(0.2))\n","    \n","    model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n","    model.add(????(0.2))\n","    \n","    model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n","    model.add(????(0.2))\n","    \n","    model.add(Dense(256, kernel_initializer='normal', activation='relu'))\n","    model.add(????(0.2))\n","    \n","    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n","    \n","    # compile model\n","    sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"58BeovzhJ59T","colab_type":"code","colab":{}},"source":["# build the model\n","model = deep_perceptron_model_with_relu_dropout()\n","model.summary()\n","\n","# fix random seed for reproductibility\n","seed = 7\n","np.random.seed(seed)\n","\n","# Fit the model\n","hist = model.fit(trainX, trainY, validation_data=(valX, valY), epochs=20, batch_size=64, verbose=2)\n","model.save('deep_perceptron_model_with_dropout.h5')\n","\n","# 5. 학습과정 살펴보기\n","fig, loss_ax = plt.subplots()\n","\n","acc_ax = loss_ax.twinx()\n","\n","loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n","loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n","loss_ax.set_ylim([0.0, 1.5])\n","\n","acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n","acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n","acc_ax.set_ylim([0.5, 1.0])\n","\n","loss_ax.set_xlabel('epoch')\n","loss_ax.set_ylabel('loss')\n","acc_ax.set_ylabel('accuray')\n","\n","loss_ax.legend(loc='upper left')\n","acc_ax.legend(loc='lower left')\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6cIJuuuENAPP","colab_type":"code","colab":{}},"source":["# Final evaluation of the model\n","scores = model.evaluate(testX, testY, verbose=0)\n","print(\"Perceptron model with relu and dropout error: %.2f%%\" % (100-scores[1]*100))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E955lLUboIsU","colab_type":"text"},"source":["#STEP 11: 네번째 인공지능 모델 (CNN)\n","\n","![대체 텍스트](https://www.mdpi.com/entropy/entropy-19-00242/article_deploy/html/images/entropy-19-00242-g001.png)"]},{"cell_type":"markdown","metadata":{"id":"CybrZ58MpVGW","colab_type":"text"},"source":["\n","# 중요! 입력데이터의 형태가 바뀌어야 한다. \n","# 784 (1D) -> 28x28 (2D)"]},{"cell_type":"code","metadata":{"id":"R106wlxMFocV","colab_type":"code","colab":{}},"source":["# reshape to be [samples][pixels][width][height]\n","trainX = trainX.reshape(50000, 28, 28, 1)\n","valX = valX.reshape(10000, 28, 28, 1)\n","testX = testX.reshape(10000, 28, 28, 1)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"X2xGLQt0FocX","colab_type":"code","colab":{}},"source":["def simple_cnn_model():\n","    # create model    \n","    model = Sequential()\n","    \n","    model.add(Conv2D(32, (5,5), input_shape=(28, 28, 1), activation='relu'))\n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    \n","    model.add(Flatten())\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dense(num_classes, activation='softmax'))\n","    \n","    # Compile model\n","    sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7Y1YC0c-Foca","colab_type":"code","colab":{}},"source":["# build the model\n","model = simple_cnn_model()\n","model.summary()\n","\n","# fix random seed for reproductibility\n","seed = 7\n","np.random.seed(seed)\n","\n","# Fit the model\n","hist = model.fit(trainX, trainY, validation_data=(valX, valY), epochs=20, batch_size=64, verbose=2)\n","model.save('simple_cnn_model.h5')\n","\n","# 5. 학습과정 살펴보기\n","fig, loss_ax = plt.subplots()\n","\n","acc_ax = loss_ax.twinx()\n","\n","loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n","loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n","loss_ax.set_ylim([0.0, 1.5])\n","\n","acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n","acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n","acc_ax.set_ylim([0.5, 1.0])\n","\n","loss_ax.set_xlabel('epoch')\n","loss_ax.set_ylabel('loss')\n","acc_ax.set_ylabel('accuray')\n","\n","loss_ax.legend(loc='upper left')\n","acc_ax.legend(loc='lower left')\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ttpPwLW4Focd","colab_type":"code","colab":{}},"source":["# Final evaluation of the model\n","scores = model.evaluate(testX, testY, verbose=0)\n","print(\"2D simple CNN error: %.2f%%\" % (100-scores[1]*100))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-ae0K65Z1IQi","colab_type":"text"},"source":["#STEP 12: Convolution kernel 살펴보기 (5x5)"]},{"cell_type":"code","metadata":{"id":"Uf5fPXX_Focf","colab_type":"code","colab":{}},"source":["W1 = model.layers[0].get_weights()[0]\n","W1 = np.squeeze(W1)\n","\n","print(W1.shape)\n","W1 = np.transpose(W1, (2,0,1))\n","\n","plt.figure(figsize=(15, 15), frameon=False)\n","for ind, val in enumerate(W1):\n","    plt.subplot(6, 6, ind + 1)\n","    im = val.reshape((5,5))\n","    plt.axis(\"off\")\n","    plt.imshow(im, cmap='gray',interpolation='nearest')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tdy-keR_Foch","colab_type":"code","colab":{}},"source":["convout1_f = K.function([model.layers[0].input], [model.layers[1].output])\n","\n","x_rep = convout1_f([testX[0:3]])\n","x_rep = np.squeeze(x_rep)\n","\n","print(x_rep.shape)\n","\n","for this_x_rep in x_rep:\n","    plt.figure(figsize=(15, 15), frameon=False)\n","    \n","    for i in range (this_x_rep.shape[2]):\n","        val = this_x_rep[:,:,i]\n","        plt.subplot(6, 6, i + 1)\n","        plt.axis(\"off\")\n","        plt.imshow(val, cmap='gray',interpolation='nearest')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OhErkuAD1laZ","colab_type":"text"},"source":["#STEP 13: 마지막 인공지능 모델 (VGG-like CNN)\n","\n","![대체 텍스트](https://neurohive.io/wp-content/uploads/2018/11/vgg16-1-e1542731207177.png)"]},{"cell_type":"code","metadata":{"id":"zBIhP_xVFock","colab_type":"code","colab":{}},"source":["def cnn_model():\n","    # create model\n","    model = Sequential()\n","    \n","    model.add(Conv2D(32, (3,3), input_shape=(28, 28, 1)))\n","    model.add(BatchNormalization())\n","    model.add(Activation(activation='relu'))\n","    \n","    model.add(Conv2D(32, (3,3)))\n","    model.add(BatchNormalization())\n","    model.add(Activation(activation='relu'))\n","    \n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    \n","    model.add(Conv2D(64, (3,3)))\n","    model.add(BatchNormalization())\n","    model.add(Activation(activation='relu'))\n","    \n","    model.add(Conv2D(64, (3,3)))\n","    model.add(BatchNormalization())\n","    model.add(Activation(activation='relu'))\n","    \n","    model.add(MaxPooling2D(pool_size=(2,2)))\n","    \n","    model.add(Flatten())\n","    model.add(Dense(128, activation='relu'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(num_classes, activation='softmax'))\n","    \n","    # Compile model\n","    sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n","    model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3OB5CedfFocl","colab_type":"code","colab":{}},"source":["# build the model\n","model = cnn_model()\n","\n","# fix random seed for reproductibility\n","seed = 7\n","np.random.seed(seed)\n","\n","# Fit the model\n","hist = model.fit(trainX, trainY, validation_data=(valX, valY), epochs=20, batch_size=64, verbose=2)\n","model.save('cnn_model.h5')\n","\n","# 5. 학습과정 살펴보기\n","fig, loss_ax = plt.subplots()\n","\n","acc_ax = loss_ax.twinx()\n","\n","loss_ax.plot(hist.history['loss'], 'y', label='train loss')\n","loss_ax.plot(hist.history['val_loss'], 'r', label='val loss')\n","loss_ax.set_ylim([0.0, 1.5])\n","\n","acc_ax.plot(hist.history['acc'], 'b', label='train acc')\n","acc_ax.plot(hist.history['val_acc'], 'g', label='val acc')\n","acc_ax.set_ylim([0.5, 1.0])\n","\n","loss_ax.set_xlabel('epoch')\n","loss_ax.set_ylabel('loss')\n","acc_ax.set_ylabel('accuray')\n","\n","loss_ax.legend(loc='upper left')\n","acc_ax.legend(loc='lower left')\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FR3ZmGKkFocn","colab_type":"code","colab":{}},"source":["# Final evaluation of the model\n","scores = model.evaluate(testX, testY, verbose=0)\n","print(\"VGG-like CNN error: %.2f%%\" % (100-scores[1]*100))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BM17JvSG1_y_","colab_type":"text"},"source":["#STEP 14: 결과 확인하기 (틀린 것 들만)"]},{"cell_type":"code","metadata":{"id":"yMnR251GFocp","colab_type":"code","colab":{}},"source":["# 7. 모델 사용하기\n","yhat_test = model.predict(testX, batch_size=32)\n","\n","plt_row = 5\n","plt_col = 5\n","\n","plt.rcParams[\"figure.figsize\"] = (20,20)\n","\n","f, axarr = plt.subplots(plt_row, plt_col)\n","\n","cnt = 0\n","i = 0\n","\n","while cnt < (plt_row*plt_col):\n","    \n","    if np.argmax(testY[i]) == np.argmax(yhat_test[i]):\n","        i += 1\n","        continue\n","    \n","    sub_plt = axarr[(int)(cnt/plt_row), cnt%plt_col]\n","    sub_plt.axis('off')\n","    sub_plt.imshow(testX[i].reshape(width, height), cmap='gray')\n","    sub_plt_title = 'R: ' + labelNames[np.argmax(testY[i])] + '(%.2f)'% (yhat_test[i][np.argmax(testY[i])]) + ' P: ' + labelNames[np.argmax(yhat_test[i])] + '(%.2f)'% (  yhat_test[i][np.argmax(yhat_test[i])])\n","    sub_plt.set_title(sub_plt_title)\n","\n","    i += 1    \n","    cnt += 1\n","\n","plt.show()"],"execution_count":0,"outputs":[]}]}